{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sadra-barikbin/persian-sentiment-analysis-example/blob/main/sentiment-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY0mx4pxnvWT"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTuTM0pgtjjp"
   },
   "outputs": [],
   "source": [
    "!pip install clean-text[gpl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "naughty-milton"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cleantext\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a18VhnUanxhq"
   },
   "source": [
    "# Loading & Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "attached-chocolate"
   },
   "outputs": [],
   "source": [
    "!gdown 'https://drive.google.com/uc?id=1HH8QFDcvkKfnj4dWmFQceb3PpNqDD8HQ&authuser=0&export=download'\n",
    "!gdown 'https://drive.google.com/uc?id=1uDOO8RP7Lr9qcRJO8z3d10qm_UggJv4I&authuser=0&export=download'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "christian-number"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "eval_df = pd.read_csv('eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0Mcw7kGmoWyi",
    "outputId": "cb42e531-39c4-4bc6-caa0-a5d88f2a8009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2587</td>\n",
       "      <td>پردازنده های Core i5 و Core i3 نیز ذاتا دو هست...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22591</td>\n",
       "      <td>سلام به دوستای عزیزم \\nعزاداری هاتون قبول باشه</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141037</td>\n",
       "      <td>کلا پولتون رو دور نریزیزد</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58593</td>\n",
       "      <td>از صمیم قلب امیدوارم دایانا با کارن بمونه و پو...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5712</td>\n",
       "      <td>آنطور که اپل ادعا می کند آیپاد شافل دارای طراح...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            comment  rate\n",
       "0        2587  پردازنده های Core i5 و Core i3 نیز ذاتا دو هست...   0.0\n",
       "1       22591     سلام به دوستای عزیزم \\nعزاداری هاتون قبول باشه   1.0\n",
       "2      141037                          کلا پولتون رو دور نریزیزد  -1.0\n",
       "3       58593  از صمیم قلب امیدوارم دایانا با کارن بمونه و پو...   1.0\n",
       "4        5712  آنطور که اپل ادعا می کند آیپاد شافل دارای طراح...   1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "L4tBlfcToYmg",
    "outputId": "78b5e684-f6ce-41d1-cea2-d481f44b4463"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61591</td>\n",
       "      <td>کیفیت غذا و زمان رسیدن عالی بود</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50299</td>\n",
       "      <td>در‌ حد ساندویچ یه نفره بود نه دونفره یا بمب. ک...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2777</td>\n",
       "      <td>طعم پیتزای چهار فصل مثل همشه خیلی خوب بود اما ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9126</td>\n",
       "      <td>مشخصات سخت افزاری مناسب در کنار سیستم عامل وین...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7544</td>\n",
       "      <td>مرغش سوخاری و خوشمزه بود، بسته بندی عالی، قیمت...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            comment  rate\n",
       "0       61591                    کیفیت غذا و زمان رسیدن عالی بود  -1.0\n",
       "1       50299  در‌ حد ساندویچ یه نفره بود نه دونفره یا بمب. ک...   1.0\n",
       "2        2777  طعم پیتزای چهار فصل مثل همشه خیلی خوب بود اما ...  -1.0\n",
       "3        9126  مشخصات سخت افزاری مناسب در کنار سیستم عامل وین...   0.5\n",
       "4        7544  مرغش سوخاری و خوشمزه بود، بسته بندی عالی، قیمت...  -1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9hppW6kwoc9N"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(train_df.columns[0], axis=1)\n",
    "eval_df = eval_df.drop(eval_df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIVevpfPonAK",
    "outputId": "233e883d-8f34-4c75-c631-1acc60687d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 out of 800 train comments have rate zero.\n",
      "30 out of 200 eval comments have rate zero.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_df[train_df.rate == 0])} out of {len(train_df)} train comments have rate zero.\")\n",
    "print(f\"{len(eval_df[eval_df.rate == 0])} out of {len(eval_df)} eval comments have rate zero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fN3mSVdDp656"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.rate != 0]\n",
    "eval_df  = eval_df[eval_df.rate != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7QKtjCFpo9xI"
   },
   "outputs": [],
   "source": [
    "train_df['rate'] = train_df.rate.apply(lambda r: 1 if r > 0 else 0)\n",
    "eval_df['rate'] = eval_df.rate.apply(lambda r: 1 if r > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ppN5iFXqUqC"
   },
   "source": [
    "## Balancing Dataset\n",
    "As you can see below, data is imbalanced. We use over-sampling strategy on negative class to mitigate the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "7UcccdyZrvkJ",
    "outputId": "00abcb47-05f6-4b28-9a1b-3781ab13ecce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  eval\n",
       "1    502   115\n",
       "0    194    55"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_df.rate.value_counts().rename('train'),\n",
    "           eval_df.rate.value_counts().rename('eval')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Kawgs4h-q01l"
   },
   "outputs": [],
   "source": [
    "balancer = RandomOverSampler(random_state=41)\n",
    "train_df, _ = balancer.fit_resample(train_df, train_df.rate)\n",
    "eval_df, _ = balancer.fit_resample(eval_df, eval_df.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_EwWGNEtZpE"
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eCIhQtnNtcqC"
   },
   "outputs": [],
   "source": [
    "params = {'to_ascii':False, 'no_urls':True,    'no_phone_numbers':True, 'no_line_breaks':True,\n",
    "          'no_emails':True, 'no_numbers':True, 'no_digits':True,        'no_currency_symbols':True}\n",
    "\n",
    "train_df['comment'] = train_df.comment.apply(lambda c: cleantext.clean(c,**params))\n",
    "eval_df['comment'] = eval_df.comment.apply(lambda c: cleantext.clean(c,**params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60669"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"vocab.txt\") as fp:\n",
    "    words = set([w.strip() for w in fp.readlines()][2:])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for c in pd.concat([train_df['comment'], eval_df['comment']]):\n",
    "    words.update(word_tokenize(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.txt', 'w') as fw:\n",
    "    for w in vocab:\n",
    "        fw.write(w + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60671"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcU7TIPZ2pfG"
   },
   "source": [
    "# Method 1: Linear Models\n",
    "We make use of Logistic Regression and SVM as classifiers, and for vectorizing the comments, Tfidf is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "v2_juBOy3xIW"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "XOPXtNPEww7e"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('embedding', vectorizer),\n",
    "                     ('classifier', 'passthrough')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHTNpGAl4LDP"
   },
   "source": [
    "## Hyper-parameter Tuning\n",
    "We search over different settings and find the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "6_XBYuBT4R0V"
   },
   "outputs": [],
   "source": [
    "param_grid = {'embedding__ngram_range': [(1,2),(1,3),(1,4)],\n",
    "              'embedding__max_features': range(100, 3000, 100),\n",
    "              'classifier': [SVC(),LogisticRegression()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rnv3weP4-gP",
    "outputId": "a0ff94b1-5daf-4f67-f67e-d982a29a487f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 174 candidates, totalling 174 fits\n"
     ]
    }
   ],
   "source": [
    "# The smelling code here is due to Scikit GridSearchCV's specific input for `cv` parameter.\n",
    "# GridSearchCV and other meta-estimators in Scikit accept whole data (train+eval) in their `fit`\n",
    "# method. So if you have a dataset separated in train and eval parts beforehand, you should\n",
    "# concatenate them. Beside that you have to give indices of train and eval parts as the `cv` parameter.\n",
    "\n",
    "train_eval = pd.concat((train, eval), ignore_index=True)\n",
    "train_eval_indices = [(train.index, eval.index + len(train))]\n",
    "meta_estimator = GridSearchCV(pipeline, param_grid, scoring=['accuracy', 'f1'],\n",
    "                              cv=train_eval_indices, refit='f1', verbose=1)\n",
    "_ = meta_estimator.fit(train_eval.comment, train_eval.rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxJhaX4YDuhs",
    "outputId": "0dd5932f-5a9a-4c08-9302-ee6e3d1c2a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(),\n",
       " 'embedding__max_features': 500,\n",
       " 'embedding__ngram_range': (1, 4)}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsTd-cnTD8SJ",
    "outputId": "aebc2d53-f201-4a9e-de80-8835793686f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model F1: 0.6979865771812082\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best model F1: {meta_estimator.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3obiJVnpEkbe"
   },
   "source": [
    "## Determining Marker Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSqPMgiBEn9H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXg2hxaADT0m"
   },
   "source": [
    "# Method 2: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MTb3Yk6_DY69"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 200\n",
    "SEQ_LEN = 64\n",
    "VOCAB_SIZE = len(vocab)\n",
    "BATCH_SIZE = 20\n",
    "CLASS_NO = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_df['comment'], train_df['rate'])).shuffle(buffer_size=len(train_df)).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "eval_ds = tf.data.Dataset.from_tensor_slices((eval_df['comment'], eval_df['rate'])).shuffle(buffer_size=len(eval_df)).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization, Embedding, Input, Dense, Bidirectional, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_lstm_model(lstm_dim=64, dense_dim=16):\n",
    "    vectorizer = TextVectorization(vocabulary='vocab.txt',\n",
    "                                   output_mode='int', \n",
    "                                   output_sequence_length=SEQ_LEN)\n",
    "    return Sequential([\n",
    "        Input(shape=(1,), dtype=tf.string),\n",
    "        vectorizer,\n",
    "        Embedding(VOCAB_SIZE + 4, EMBED_DIM, name='embedding'),\n",
    "        Bidirectional(LSTM(lstm_dim)),\n",
    "        Dense(dense_dim, activation='relu'),\n",
    "        Dense(CLASS_NO, 'softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_lstm_model()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_16 (Text  (None, 64)               0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 64, 200)           12135000  \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 128)              135680    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,272,778\n",
      "Trainable params: 12,272,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51/51 [==============================] - 15s 218ms/step - loss: 0.6750 - accuracy: 0.5817 - val_loss: 0.6640 - val_accuracy: 0.5739\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 10s 202ms/step - loss: 0.3038 - accuracy: 0.8835 - val_loss: 0.7537 - val_accuracy: 0.6522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41994e7700>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=eval_ds, epochs=10, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6iqEzrQDYG5"
   },
   "source": [
    "# Method 3: Pre-trained Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NG5EEcYELKN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "sentiment-classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
